{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dee330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os, shutil\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "​\n",
    "train_path = \"../input/vegetable-image-dataset/Vegetable Images/train\"\n",
    "validation_path = \"../input/vegetable-image-dataset/Vegetable Images/validation\"\n",
    "test_path = \"../input/vegetable-image-dataset/Vegetable Images/test\"\n",
    "​\n",
    "image_categories = os.listdir('../input/vegetable-image-dataset/Vegetable Images/train')\n",
    "​\n",
    "def plot_images(image_categories):\n",
    "    \n",
    "    # Create a figure\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    for i, cat in enumerate(image_categories):\n",
    "        \n",
    "        # Load images for the ith category\n",
    "        image_path = train_path + '/' + cat\n",
    "        images_in_folder = os.listdir(image_path)\n",
    "        first_image_of_folder = images_in_folder[0]\n",
    "        first_image_path = image_path + '/' + first_image_of_folder\n",
    "        img = image.load_img(first_image_path)\n",
    "        img_arr = image.img_to_array(img)/255.0\n",
    "        \n",
    "        \n",
    "        # Create Subplot and plot the images\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(img_arr)\n",
    "        plt.title(cat)\n",
    "        plt.axis('off')\n",
    "        \n",
    "    plt.show()\n",
    "​\n",
    "# Call the function\n",
    "plot_images(image_categories)\n",
    "​\n",
    "train_gen = ImageDataGenerator(rescale = 1.0/255.0) # Normalise the data\n",
    "train_image_generator = train_gen.flow_from_directory(\n",
    "                                            train_path,\n",
    "                                            target_size=(140, 140),\n",
    "                                            batch_size=36,\n",
    "                                            class_mode='categorical')\n",
    "​\n",
    "# 2. Validation Set\n",
    "val_gen = ImageDataGenerator(rescale = 1.0/255.0) # Normalise the data\n",
    "val_image_generator = train_gen.flow_from_directory(\n",
    "                                            validation_path,\n",
    "                                            target_size=(140, 140),\n",
    "                                            batch_size=36,\n",
    "                                            class_mode='categorical')\n",
    "​\n",
    "# 3. Test Set\n",
    "test_gen = ImageDataGenerator(rescale = 1.0/255.0) # Normalise the data\n",
    "test_image_generator = train_gen.flow_from_directory(\n",
    "                                            test_path,\n",
    "                                            target_size=(140, 140),\n",
    "                                            batch_size=36,\n",
    "                                            class_mode='categorical')\n",
    "​\n",
    "​\n",
    "model = Sequential() # model object\n",
    "​\n",
    "# Add Layers\n",
    "model.add(Conv2D(filters=48, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=[140, 140, 3]))\n",
    "model.add(MaxPooling2D(2, ))\n",
    "model.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(2))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv2D(filters=48, kernel_size=4, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(2))\n",
    "​\n",
    "model.add(Flatten())\n",
    "​\n",
    "# Add the fully connected layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(15, activation='softmax'))\n",
    "​\n",
    "# print the model summary\n",
    "model.summary()\n",
    "​\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "hist = model.fit(train_image_generator, \n",
    "                 epochs=25, \n",
    "                 verbose=1, \n",
    "                 validation_data=val_image_generator, \n",
    "                 steps_per_epoch = 15000//36, \n",
    "                 validation_steps = 3000//36,)\n",
    "​\n",
    "h = hist.history\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(h['loss'], c='red', label='Training Loss')\n",
    "plt.plot(h['val_loss'], c='red', linestyle='--', label='Validation Loss')\n",
    "plt.plot(h['accuracy'], c='blue', label='Training Accuracy')\n",
    "plt.plot(h['val_accuracy'], c='blue', linestyle='--', label='Validation Accuracy')\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "​\n",
    "model.evaluate(test_image_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
